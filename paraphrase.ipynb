{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paraphrase detection with a classifier using BERT representation\n",
    "#THis notebook is based on the Microsoft Research paraphrase corpus where a classifier is trained to detect paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.multiprocessing as torch_mp\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_segment_ids(list_of_tokens):\n",
    "    #this function assumes that up to and including the first '[SEP]' is the first segment, anything afterwards is the second segment\n",
    "    current_id=0\n",
    "    segment_ids=[]\n",
    "    for token in list_of_tokens:\n",
    "        segment_ids.append(current_id)\n",
    "        if token == '[SEP]':\n",
    "            current_id +=1\n",
    "    return segment_ids\n",
    "\n",
    "def tokenize(text):\n",
    "    text = 'CLS' + text + 'SEP'\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    seg = make_segment_ids(tokens)\n",
    "\n",
    "    return ids, seg\n",
    "\n",
    "def load_tsv(tsv_text):\n",
    "    content = dict()\n",
    "   \n",
    "    temp1 = []; temp2 = []; temp3 = []; temp4 = []; temp5 = []\n",
    "    with open(tsv_text, 'r') as tr:\n",
    "        for line in tr:\n",
    "            line = line.split('\\t')\n",
    "            temp1.append(line[0])\n",
    "            temp2.append(line[1])\n",
    "            temp3.append(line[2])\n",
    "            temp4.append(line[3])\n",
    "            temp5.append(line[4])\n",
    "\n",
    "    content[\"Quality\"] = temp1[1:]; content[\"#1 ID\"] = temp2[1:]; content[\"#2 ID\"] = temp3[1:]\n",
    "    content[\"#1 String\"] = temp4[1:]; content[\"#2 String\"] = temp5[1:]\n",
    "\n",
    "    return content\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    \"\"\"Plotting confusion matrix given predicted y(y_pred), true y(y_true) and labels\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_preds, labels, normalize= True)\n",
    "    fig,ax = plt.subplots(len(labels), len(labels))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels= labels)\n",
    "    disp.plot(cmap= \"Blues\", values_format =\".2f\", ax = ax, colorbar = False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "def cross_val_w_gridsearch(x, y, model, params, cv_method = KFold, num_of_splits = 8, method = \"grid\"):\n",
    "\n",
    "    \"\"\"Already defined splits, x-labels are ndarrays and Model is already initialised y - labels are also ndarrays\"\"\"\n",
    "    \n",
    "    output = []\n",
    "    try:\n",
    "        kf = cv_method(num_of_splits, shuffle = True, random_state = 10 )\n",
    "        splits = kf.split(y)\n",
    "    except ModuleNotFoundError:\n",
    "        print(\"Import {} module\".format(cv_method))\n",
    "    \n",
    "    if method.lower() == \"grid\" or \"random\":\n",
    "        print(method)\n",
    "        gridsearch = GridSearchCV(model, params, n_jobs = 10) \n",
    "\n",
    "        for train,val in splits:    \n",
    "\n",
    "            gridsearch.fit(x[train],y[train])\n",
    "            best_xgb_model = model.set_params(**gridsearch.best_params_)\n",
    "\n",
    "            best_xgb_model.fit(x[train], y[train])\n",
    "            pred = best_xgb_model.predict(x[val])\n",
    "\n",
    "            pred = np.round(pred, 0) #rounded up in order to match labels\n",
    "            ref =  y[val]\n",
    "\n",
    "            #using accuracy as a metric to evaluate models\n",
    "            f1 = f1_score(pred,ref, average = \"weighted\")\n",
    "            output.append((f1,best_xgb_model,))\n",
    "    else:\n",
    "        print(\"select either 'grid' or 'random'\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRPC = \"/users/max/Desktop/NLP/Advanced_NLP/Deep_Learning_Transformers_Week7/lab8/MRPC\"\n",
    "\n",
    "os.listdir(MRPC)\n",
    "\n",
    "train = MRPC + '/msr_paraphrase_train.txt'\n",
    "dev = MRPC + '/msr_paraphrase_dev.tsv'\n",
    "test = MRPC + '/msr_paraphrase_test.txt'\n",
    "\n",
    "label2id = {1: \"paraphrase\", 0: \"not paraphrase\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Quality\", \"#1 ID\", \"#2 ID\", \"#1 String\", \"#2 String\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.DataFrame(load_tsv(train))\n",
    "raw_dev = pd.DataFrame(load_tsv(dev))\n",
    "raw_test = pd.DataFrame(load_tsv(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining token ids using BERT Tokenizer for train,dev and test split\n",
    " \n",
    "train_1_id, train_1_seg_id = zip(*raw_train[\"#1 String\"].map(tokenize)) #unpacks \n",
    "train_2_id, train_2_seg_id= zip(*raw_train[\"#2 String\"].map(tokenize)) \n",
    "\n",
    "dev_1_id, dev_1_seg_id = zip(*raw_dev[\"#1 String\"].map(tokenize)) \n",
    "dev_2_id, dev_2_seg_id = zip(*raw_dev[\"#2 String\"].map(tokenize)) \n",
    "\n",
    "test_1_id, test_1_seg_id = zip(*raw_test[\"#1 String\"].map(tokenize))\n",
    "test_2_id, test_2_seg_id  = zip(*raw_test[\"#2 String\"].map(tokenize))\n",
    "\n",
    "#Obtaining labels to be used in classification head\n",
    "train_labels = raw_train[\"Quality\"]; dev_labels = raw_dev[\"Quality\"]; test_labels = raw_test[\"Quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def out_hidden_states(text, flag = \"tensor\"):\n",
    "\n",
    "    \"\"\"Switches between Arrays and Tensors\"\"\"\n",
    "\n",
    "    input = tokenizer(text, return_tensors =\"pt\")\n",
    "    ins = {k:v.to(device) for k,v in input.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(**ins)[-2]\n",
    "\n",
    "        if flag == \"array\":\n",
    "            out = out[:,0].cpu().numpy()[:,:]\n",
    "\n",
    "        elif flag == \"tensor\": \n",
    "            out = out[:, 0]\n",
    "\n",
    "        else :\n",
    "            print(\"select 'tensor' or 'array' \")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>702876</td>\n",
       "      <td>702977</td>\n",
       "      <td>Amrozi accused his brother , whom he called \" ...</td>\n",
       "      <td>Referring to him as only \" the witness \" , Amr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2108705</td>\n",
       "      <td>2108831</td>\n",
       "      <td>Yucaipa owned Dominick 's before selling the c...</td>\n",
       "      <td>Yucaipa bought Dominick 's in 1995 for $ 693 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1330381</td>\n",
       "      <td>1330521</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10 , the ship 's owners had published ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3344667</td>\n",
       "      <td>3344648</td>\n",
       "      <td>Around 0335 GMT , Tab shares were up 19 cents ...</td>\n",
       "      <td>Tab shares jumped 20 cents , or 4.6 % , to set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1236820</td>\n",
       "      <td>1236712</td>\n",
       "      <td>The stock rose $ 2.11 , or about 11 percent , ...</td>\n",
       "      <td>PG &amp; E Corp. shares jumped $ 1.63 or 8 percent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>1</td>\n",
       "      <td>1620264</td>\n",
       "      <td>1620507</td>\n",
       "      <td>\" At this point , Mr. Brando announced : ' Som...</td>\n",
       "      <td>Brando said that \" somebody ought to put a bul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>0</td>\n",
       "      <td>1848001</td>\n",
       "      <td>1848224</td>\n",
       "      <td>Martin , 58 , will be freed today after servin...</td>\n",
       "      <td>Martin served two thirds of a five-year senten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>1</td>\n",
       "      <td>747160</td>\n",
       "      <td>747144</td>\n",
       "      <td>\" We have concluded that the outlook for price...</td>\n",
       "      <td>In a statement , the ECB said the outlook for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>1</td>\n",
       "      <td>2539933</td>\n",
       "      <td>2539850</td>\n",
       "      <td>The notification was first reported Friday by ...</td>\n",
       "      <td>MSNBC.com first reported the CIA request on Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>0</td>\n",
       "      <td>453575</td>\n",
       "      <td>453448</td>\n",
       "      <td>The 30-year bond US30YT = RR rose 22 / 32 for ...</td>\n",
       "      <td>The 30-year bond US30YT = RR grew 1-3 / 32 for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4076 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Quality    #1 ID    #2 ID  \\\n",
       "0          1   702876   702977   \n",
       "1          0  2108705  2108831   \n",
       "2          1  1330381  1330521   \n",
       "3          0  3344667  3344648   \n",
       "4          1  1236820  1236712   \n",
       "...      ...      ...      ...   \n",
       "4071       1  1620264  1620507   \n",
       "4072       0  1848001  1848224   \n",
       "4073       1   747160   747144   \n",
       "4074       1  2539933  2539850   \n",
       "4075       0   453575   453448   \n",
       "\n",
       "                                              #1 String  \\\n",
       "0     Amrozi accused his brother , whom he called \" ...   \n",
       "1     Yucaipa owned Dominick 's before selling the c...   \n",
       "2     They had published an advertisement on the Int...   \n",
       "3     Around 0335 GMT , Tab shares were up 19 cents ...   \n",
       "4     The stock rose $ 2.11 , or about 11 percent , ...   \n",
       "...                                                 ...   \n",
       "4071  \" At this point , Mr. Brando announced : ' Som...   \n",
       "4072  Martin , 58 , will be freed today after servin...   \n",
       "4073  \" We have concluded that the outlook for price...   \n",
       "4074  The notification was first reported Friday by ...   \n",
       "4075  The 30-year bond US30YT = RR rose 22 / 32 for ...   \n",
       "\n",
       "                                              #2 String  \n",
       "0     Referring to him as only \" the witness \" , Amr...  \n",
       "1     Yucaipa bought Dominick 's in 1995 for $ 693 m...  \n",
       "2     On June 10 , the ship 's owners had published ...  \n",
       "3     Tab shares jumped 20 cents , or 4.6 % , to set...  \n",
       "4     PG & E Corp. shares jumped $ 1.63 or 8 percent...  \n",
       "...                                                 ...  \n",
       "4071  Brando said that \" somebody ought to put a bul...  \n",
       "4072  Martin served two thirds of a five-year senten...  \n",
       "4073  In a statement , the ECB said the outlook for ...  \n",
       "4074  MSNBC.com first reported the CIA request on Fr...  \n",
       "4075  The 30-year bond US30YT = RR grew 1-3 / 32 for...  \n",
       "\n",
       "[4076 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking function per input\n",
    "out_hidden_states(raw_train['#1 String'][0]).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING NEURAL LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_string_1 = raw_train[\"#1 String\"]\n",
    "train_string_2 = raw_train['#2 String']\n",
    "\n",
    "dev_string_1 = raw_dev['#1 String']\n",
    "dev_string_2 = raw_dev['#2 String']\n",
    "\n",
    "test_string_1 = raw_test['#1 String']\n",
    "test_string_2 = raw_test['#2 String']\n",
    "\n",
    "train_string_1 = [out_hidden_states(text, flag = \"tensor\") for text in train_string_1]\n",
    "train_string_1 = torch.cat(train_string_1, dim = 0)\n",
    "\n",
    "train_string_2 = [out_hidden_states(text, flag = \"tensor\") for text in train_string_2]\n",
    "train_string_2 = torch.cat(train_string_2, dim = 0)\n",
    "\n",
    "dev_string_1 = [out_hidden_states(text, flag = \"tensor\") for text in dev_string_1]\n",
    "dev_string_1 = torch.cat(dev_string_1, dim = 0)\n",
    "\n",
    "dev_string_2 = [out_hidden_states(text, flag = \"tensor\") for text in dev_string_2]\n",
    "dev_string_2 = torch.cat(dev_string_2, dim = 0)\n",
    "\n",
    "test_string_1 = [out_hidden_states(text, flag = \"tensor\") for text in test_string_1]\n",
    "test_string_1 = torch.cat(test_string_1, dim = 0)\n",
    "\n",
    "test_string_2 = [out_hidden_states(text, flag = \"tensor\") for text in test_string_2]\n",
    "test_string_2 = torch.cat(test_string_2, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.cat((train_string_1, train_string_2), dim = 1)\n",
    "dev = torch.cat((dev_string_1, dev_string_2), dim = 1)\n",
    "test  = torch.cat((test_string_1, test_string_2), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4076, 1536])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class pp_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(768*2,2)\n",
    "        self.dropout = nn.Dropout()\n",
    "        \n",
    "    def forward(self, inputs:torch.tensor):\n",
    "        x = self.l1(inputs)\n",
    "        return x\n",
    "\n",
    "#Assess impact of dropout on classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    corr = 0\n",
    "    if len(y_true) == len(y_pred):\n",
    "        for a,b in zip(y_true, y_pred):\n",
    "            if a == b:\n",
    "                corr += 1\n",
    "            else:\n",
    "                pass\n",
    "        print(\"The Accuracy of this prediction is {}\".format(corr/len(y_true)))\n",
    "    else:\n",
    "        print(\"y_true is not the same as y_pred\")\n",
    "        pass\n",
    "    return corr/len(y_true)\n",
    "\n",
    "def accuracy_tensor(probs: torch.FloatTensor, targets: torch.LongTensor) -> float:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        probs: A float32 tensor of shape ``(batch_size, class_count)`` where each value \n",
    "            at index ``i`` in a row represents the score of class ``i``.\n",
    "        targets: A long tensor of shape ``(batch_size,)`` containing the batch examples'\n",
    "            labels.\n",
    "    \"\"\"\n",
    "    predicted = probs.argmax(dim=1)\n",
    "    corrects = (predicted == targets)\n",
    "    accuracy = corrects.sum().float() / float( targets.size(0) )\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = raw_train[\"Quality\"]\n",
    "train_labels = train_labels.map(float)\n",
    "\n",
    "paraphrase_model = pp_model()\n",
    "logits = paraphrase_model.forward(train)\n",
    "\n",
    "logits = torch.argmax(logits, dim = 1)\n",
    "output = list(logits.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of this prediction is 0.5836604514229637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x144ee3a30>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "accuracy(output, train_labels)\n",
    "ConfusionMatrixDisplay.from_predictions(train_labels, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN ON TRAIN_SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1.,  ..., 1., 1., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/kl4z85b17kd84k1hy0srlb3w0000gn/T/ipykernel_24086/992723211.py:3: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  train_labels = torch.tensor(raw_train['Quality'].map(float), dtype = torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train accuracy: 67.54, loss: 3.88844\n",
      "epoch: 1 train accuracy: 72.18, loss: 0.83615\n",
      "epoch: 2 train accuracy: 43.06, loss: 1.62465\n",
      "epoch: 3 train accuracy: 67.54, loss: 3.69859\n",
      "epoch: 4 train accuracy: 73.26, loss: 0.74140\n",
      "epoch: 5 train accuracy: 49.51, loss: 1.30256\n",
      "epoch: 6 train accuracy: 67.57, loss: 3.17526\n",
      "epoch: 7 train accuracy: 73.09, loss: 0.62014\n",
      "epoch: 8 train accuracy: 73.72, loss: 0.61559\n",
      "epoch: 9 train accuracy: 72.47, loss: 0.61876\n",
      "epoch: 10 train accuracy: 73.63, loss: 0.68011\n",
      "epoch: 11 train accuracy: 53.34, loss: 1.11318\n",
      "epoch: 12 train accuracy: 67.62, loss: 2.84428\n",
      "epoch: 13 train accuracy: 68.94, loss: 0.67780\n",
      "epoch: 14 train accuracy: 70.12, loss: 1.13091\n",
      "epoch: 15 train accuracy: 37.98, loss: 2.03015\n",
      "epoch: 16 train accuracy: 67.54, loss: 4.15574\n",
      "epoch: 17 train accuracy: 70.58, loss: 0.99942\n",
      "epoch: 18 train accuracy: 39.25, loss: 1.93269\n",
      "epoch: 19 train accuracy: 67.54, loss: 4.05038\n",
      "epoch: 20 train accuracy: 71.25, loss: 0.93274\n",
      "epoch: 21 train accuracy: 40.51, loss: 1.82425\n",
      "epoch: 22 train accuracy: 67.54, loss: 3.92663\n",
      "epoch: 23 train accuracy: 72.01, loss: 0.85960\n",
      "epoch: 24 train accuracy: 42.64, loss: 1.66733\n",
      "epoch: 25 train accuracy: 67.54, loss: 3.73632\n",
      "epoch: 26 train accuracy: 73.14, loss: 0.76030\n",
      "epoch: 27 train accuracy: 48.28, loss: 1.36456\n",
      "epoch: 28 train accuracy: 67.54, loss: 3.27616\n",
      "epoch: 29 train accuracy: 73.92, loss: 0.62481\n",
      "epoch: 30 train accuracy: 71.44, loss: 0.64451\n",
      "epoch: 31 train accuracy: 72.25, loss: 0.82965\n",
      "epoch: 32 train accuracy: 42.69, loss: 1.64133\n",
      "epoch: 33 train accuracy: 67.54, loss: 3.74393\n",
      "epoch: 34 train accuracy: 73.14, loss: 0.75537\n",
      "epoch: 35 train accuracy: 47.11, loss: 1.39136\n",
      "epoch: 36 train accuracy: 67.54, loss: 3.36324\n",
      "epoch: 37 train accuracy: 73.92, loss: 0.62868\n",
      "epoch: 38 train accuracy: 67.30, loss: 0.71851\n",
      "epoch: 39 train accuracy: 69.60, loss: 1.32736\n",
      "epoch: 40 train accuracy: 39.30, loss: 1.93568\n",
      "epoch: 41 train accuracy: 67.54, loss: 4.04395\n",
      "epoch: 42 train accuracy: 71.34, loss: 0.92879\n",
      "epoch: 43 train accuracy: 40.65, loss: 1.81077\n",
      "epoch: 44 train accuracy: 67.54, loss: 3.90512\n",
      "epoch: 45 train accuracy: 72.08, loss: 0.84706\n",
      "epoch: 46 train accuracy: 43.30, loss: 1.63324\n",
      "epoch: 47 train accuracy: 67.54, loss: 3.68725\n",
      "epoch: 48 train accuracy: 73.41, loss: 0.73743\n",
      "epoch: 49 train accuracy: 50.44, loss: 1.27473\n",
      "epoch: 50 train accuracy: 67.57, loss: 3.09959\n",
      "epoch: 51 train accuracy: 72.84, loss: 0.62302\n",
      "epoch: 52 train accuracy: 74.02, loss: 0.64353\n",
      "epoch: 53 train accuracy: 62.46, loss: 0.82593\n",
      "epoch: 54 train accuracy: 68.60, loss: 1.83848\n",
      "epoch: 55 train accuracy: 45.34, loss: 1.47593\n",
      "epoch: 56 train accuracy: 67.54, loss: 3.50802\n",
      "epoch: 57 train accuracy: 73.99, loss: 0.66158\n",
      "epoch: 58 train accuracy: 58.51, loss: 0.94618\n",
      "epoch: 59 train accuracy: 68.16, loss: 2.29158\n",
      "epoch: 60 train accuracy: 56.31, loss: 1.02963\n",
      "epoch: 61 train accuracy: 67.93, loss: 2.54820\n",
      "epoch: 62 train accuracy: 62.66, loss: 0.82871\n",
      "epoch: 63 train accuracy: 68.62, loss: 1.84074\n",
      "epoch: 64 train accuracy: 45.51, loss: 1.46164\n",
      "epoch: 65 train accuracy: 67.54, loss: 3.48092\n",
      "epoch: 66 train accuracy: 74.21, loss: 0.65601\n",
      "epoch: 67 train accuracy: 60.21, loss: 0.90426\n",
      "epoch: 68 train accuracy: 68.25, loss: 2.14036\n",
      "epoch: 69 train accuracy: 52.36, loss: 1.16135\n",
      "epoch: 70 train accuracy: 67.64, loss: 2.89478\n",
      "epoch: 71 train accuracy: 70.88, loss: 0.65654\n",
      "epoch: 72 train accuracy: 71.22, loss: 0.93521\n",
      "epoch: 73 train accuracy: 40.11, loss: 1.84087\n",
      "epoch: 74 train accuracy: 67.54, loss: 3.96299\n",
      "epoch: 75 train accuracy: 71.96, loss: 0.87916\n",
      "epoch: 76 train accuracy: 41.68, loss: 1.72143\n",
      "epoch: 77 train accuracy: 67.54, loss: 3.81682\n",
      "epoch: 78 train accuracy: 72.60, loss: 0.79865\n",
      "epoch: 79 train accuracy: 44.97, loss: 1.50707\n",
      "epoch: 80 train accuracy: 67.54, loss: 3.52357\n",
      "epoch: 81 train accuracy: 73.95, loss: 0.67361\n",
      "epoch: 82 train accuracy: 57.63, loss: 0.98227\n",
      "epoch: 83 train accuracy: 68.16, loss: 2.37450\n",
      "epoch: 84 train accuracy: 58.93, loss: 0.94664\n",
      "epoch: 85 train accuracy: 68.20, loss: 2.25535\n",
      "epoch: 86 train accuracy: 56.11, loss: 1.04335\n",
      "epoch: 87 train accuracy: 67.98, loss: 2.55329\n",
      "epoch: 88 train accuracy: 63.52, loss: 0.81646\n",
      "epoch: 89 train accuracy: 68.89, loss: 1.75581\n",
      "epoch: 90 train accuracy: 44.85, loss: 1.52039\n",
      "epoch: 91 train accuracy: 67.54, loss: 3.54479\n",
      "epoch: 92 train accuracy: 73.90, loss: 0.68200\n",
      "epoch: 93 train accuracy: 56.48, loss: 1.02591\n",
      "epoch: 94 train accuracy: 68.03, loss: 2.50521\n",
      "epoch: 95 train accuracy: 62.22, loss: 0.84639\n",
      "epoch: 96 train accuracy: 68.62, loss: 1.88319\n",
      "epoch: 97 train accuracy: 47.18, loss: 1.39074\n",
      "epoch: 98 train accuracy: 67.54, loss: 3.33761\n",
      "epoch: 99 train accuracy: 73.95, loss: 0.62920\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "train_labels = torch.tensor(raw_train['Quality'].map(float), dtype = torch.long)\n",
    "optimizer = optim.SGD(paraphrase_model.parameters(), lr=0.05)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "paraphrase_model.train()\n",
    "\n",
    "for epoch in range(0, 100):   \n",
    "\n",
    "    logits = paraphrase_model.forward(train)\n",
    "    loss = criterion(logits, train_labels)\n",
    "\n",
    "    print(\"epoch: {} train accuracy: {:2.2f}, loss: {:5.5f}\".format(epoch,accuracy_tensor(logits, train_labels) * 100,loss.item()))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot training loss chart\n",
    "#plot validation loss\n",
    "#Set up if statement for when training loss less than validation loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('nlp_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79988c4517afee57aaca61710796edfc2f44e65e763dd9b1bbd0d2f44c7b4eaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
